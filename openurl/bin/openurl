#!/usr/bin/env python

from dataclasses import dataclass
from pathlib import Path
import argparse
import logging
import re
import shlex
import subprocess
import sys

import requests

REQUEST_TIMEOUT = 1
USER_AGENT = " ".join([
    "Mozilla/5.0 (X11; Linux x86_64)",
    "AppleWebKit/537.36 (KHTML, like Gecko)",
    "Chrome/64.0.3282.140",
    "Safari/537.36",
    "openurl/1.0",
])

# re-use the session for all requests
session = requests.Session()
session.headers['User-Agent'] = USER_AGENT
log = logging.getLogger(__name__)


def main() -> int:
    logging.basicConfig(format="%(message)s", level=logging.INFO)
    params = parse_args()
    config = Config.load()
    opened_all = True
    for url in params.url:
        url = apply_replacements(config, url)

        mime_type = None
        if any(re.search(reg, url) for reg in config.noreq):
            log.info(f"Skipping request due to a `noreq:` match.")
        else:
            new_url, mime_type = make_request(url)
            if not new_url:
                continue
            url = new_url
        opened_all &= open_url(config, url, mime_type)
    return 0 if opened_all else 1


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser()
    parser.add_argument("url", nargs="+")
    return parser.parse_args()


@dataclass
class Config:
    repl: list[tuple[re.Pattern, str]]
    noreq: list[str]
    patterns: list[tuple[str, str]]

    @classmethod
    def load(cls) -> 'Config':
        config = cls([], [], [])
        with Path("~/.config/openurl.conf").expanduser().open() as f:
            for i, line in enumerate(f):
                if not (stripped := line.strip()) or stripped.startswith("#"):
                    continue  # Discard empty and commented lines
                try:
                    if stripped.startswith("noreq:"):
                        config.noreq.append(stripped.removeprefix("noreq:"))
                    elif stripped.startswith("nohead:"):
                        log.warning("Found a `nohead:` line in config. This is deprecated and ignored.")
                    elif stripped.startswith("repl:"):
                        pattern, replacement = stripped[5:].split(maxsplit=1)
                        assert pattern and replacement
                        config.repl.append((re.compile(pattern), replacement))
                    else:
                        pattern, command = stripped.split(maxsplit=1)
                        assert pattern and command
                        config.patterns.append((pattern, command))
                except Exception as e:
                    log.error(f"Bad line {i + 1}: {stripped!r}")
                    raise e  # for the full traceback
        return config


def notify(summary, body=""):
    args = ["notify-send", "--app-name=openurl", summary]
    if body:
        args.append(body)
    subprocess.Popen(args)


def open_url(config: Config, url: str, mime_type: str | None) -> bool:
    for reg, cmd in config.patterns:
        if reg.startswith("mime:"):
            reg = reg[5:]
            if not mime_type or not re.search(reg, mime_type):
                continue
            log.info(f"MIME type {mime_type!r} matched by `{reg!s}`")
        elif not re.search(reg, url):
            continue
        else:
            log.info(f"URL matched by `{reg!s}`")

        if "{url}" in cmd:
            args = shlex.split(cmd.format(url=url))
        else:
            args = shlex.split(cmd) + [url]
        log.info(f"Opening {url!r} with `{cmd}`")
        subprocess.Popen(args)
        return True
    else:
        # You don't want this to happen
        log.error(f"No regex match for {url!r}")
        return False


def apply_replacements(config: Config, url: str) -> str:
    for reg_pattern, sub in config.repl:
        if re.search(reg_pattern, url):
            new_url = re.sub(reg_pattern, sub, url)
            log.info(f"Replaced {url!r} with {new_url!r}")
            url = new_url
    return url


def make_request(url: str) -> tuple[str | None, str | None]:
    try:
        with session.get(
            url,
            timeout=REQUEST_TIMEOUT,
            allow_redirects=True,
            stream=True,
            headers={'User-Agent': USER_AGENT},
        ) as res:
            content_type = res.headers.get('content-type')
            code = res.status_code
            log.info(f"GET response: {code}")
            if res.url != url:
                log.info(f"And previously redirected to {res.url}")
                url = res.url
    except (requests.ConnectTimeout, requests.ConnectionError, requests.ReadTimeout):
        code = 0
        log.warning(f"The request errored or timed out after {REQUEST_TIMEOUT} seconds")
        return url, None

    # https://en.wikipedia.org/wiki/List_of_HTTP_status_codes#4xx_client_errors
    if code >= 400 and code not in (401, 403, 418):
        notify(f"HTTP {code}",
               f"Server returned HTTP status code {code} for:\n{url}")
        return None, None

    mime_type = content_type.split(";", maxsplit=1)[0] if content_type else None
    return url, mime_type


if __name__ == '__main__':
    sys.exit(main())
